{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded scikit-learn model: dtree_model\n",
      "Loaded scikit-learn model: mlp_neural_net\n",
      "Loaded scikit-learn model: random_forest_model\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>AUC_ROC</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dtree_model</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.543476</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.538275</td>\n",
       "      <td>0.955129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlp_neural_net</td>\n",
       "      <td>0.898291</td>\n",
       "      <td>0.898978</td>\n",
       "      <td>0.898291</td>\n",
       "      <td>0.897737</td>\n",
       "      <td>0.996135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random_forest_model</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.372916</td>\n",
       "      <td>1.973631</td>\n",
       "      <td>0.871482</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Accuracy  Precision    Recall  F1_Score   AUC_ROC  \\\n",
       "0          dtree_model  0.555556   0.543476  0.555556  0.538275  0.955129   \n",
       "1       mlp_neural_net  0.898291   0.898978  0.898291  0.897737  0.996135   \n",
       "2  random_forest_model       NaN        NaN       NaN       NaN       NaN   \n",
       "\n",
       "        MSE       MAE        R2  \n",
       "0       NaN       NaN       NaN  \n",
       "1       NaN       NaN       NaN  \n",
       "2  7.372916  1.973631  0.871482  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    roc_auc_score,\n",
    "    mean_squared_error,\n",
    "    mean_absolute_error,\n",
    "    r2_score,\n",
    ")\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Load datasets\n",
    "X_train = pd.read_csv(\"../04_modelling/dataset/X_train.csv\")\n",
    "y_train = pd.read_csv(\"../04_modelling/dataset/y_train.csv\").squeeze()  # Convert to Series\n",
    "X_test = pd.read_csv(\"../04_modelling/dataset/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../04_modelling/dataset/y_test.csv\").squeeze()    # Convert to Series\n",
    "\n",
    "# Function to load scikit-learn models\n",
    "def load_sklearn_model(file_name):\n",
    "    with open(file_name, \"rb\") as file:\n",
    "        return joblib.load(file)\n",
    "\n",
    "# Function to record evaluation scores\n",
    "def record_scores(results_df, **metrics):\n",
    "    \"\"\"\n",
    "    Append evaluation scores to the results DataFrame.\n",
    "    \"\"\"\n",
    "    new_row = pd.DataFrame([metrics])\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "    return results_df\n",
    "\n",
    "# Ensure y datasets are flattened\n",
    "y_train = y_train.values.ravel()\n",
    "y_test = y_test.values.ravel()\n",
    "\n",
    "# Function to evaluate models\n",
    "def evaluate_models(models, X_test, y_test, results_df):\n",
    "    \"\"\"\n",
    "    Evaluate models and handle specific preprocessing requirements.\n",
    "    \"\"\"\n",
    "    for model_name, model in models.items():\n",
    "        try:\n",
    "            if isinstance(model, RandomForestRegressor):  # Handle regression models\n",
    "                predictions = model.predict(X_test)\n",
    "                \n",
    "                # Regression metrics\n",
    "                mse = mean_squared_error(y_test, predictions)\n",
    "                mae = mean_absolute_error(y_test, predictions)\n",
    "                r2 = r2_score(y_test, predictions)\n",
    "                \n",
    "                results_df = record_scores(\n",
    "                    results_df,\n",
    "                    Model=model_name,\n",
    "                    MSE=mse,\n",
    "                    MAE=mae,\n",
    "                    R2=r2,\n",
    "                    Accuracy=None,\n",
    "                    Precision=None,\n",
    "                    Recall=None,\n",
    "                    F1_Score=None,\n",
    "                    AUC_ROC=None,\n",
    "                )\n",
    "            else:  # Handle classification models\n",
    "                predictions = model.predict(X_test)\n",
    "                predictions_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "                accuracy = accuracy_score(y_test, predictions)\n",
    "                precision = precision_score(y_test, predictions, average=\"weighted\")\n",
    "                recall = recall_score(y_test, predictions, average=\"weighted\")\n",
    "                f1 = f1_score(y_test, predictions, average=\"weighted\")\n",
    "                \n",
    "                # Handle AUC-ROC\n",
    "                if predictions_proba is not None and len(set(y_test)) > 2:\n",
    "                    auc_roc = roc_auc_score(pd.get_dummies(y_test), predictions_proba, multi_class=\"ovr\")\n",
    "                elif predictions_proba is not None:\n",
    "                    auc_roc = roc_auc_score(y_test, predictions_proba[:, 1])\n",
    "                else:\n",
    "                    auc_roc = None\n",
    "\n",
    "                results_df = record_scores(\n",
    "                    results_df,\n",
    "                    Model=model_name,\n",
    "                    Accuracy=accuracy,\n",
    "                    Precision=precision,\n",
    "                    Recall=recall,\n",
    "                    F1_Score=f1,\n",
    "                    AUC_ROC=auc_roc,\n",
    "                    MSE=None,\n",
    "                    MAE=None,\n",
    "                    R2=None,\n",
    "                )\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating model {model_name}: {e}\")\n",
    "    return results_df\n",
    "\n",
    "# Define scikit-learn model files\n",
    "sklearn_model_files = [\n",
    "    \"../04_modelling/models/dtree_model.pkl\",\n",
    "    \"../04_modelling/models/mlp_neural_net.pkl\",\n",
    "    \"../04_modelling/models/random_forest_model.pkl\",\n",
    "]\n",
    "\n",
    "# Load scikit-learn models\n",
    "sklearn_models = {}\n",
    "for file_name in sklearn_model_files:\n",
    "    model_name = os.path.splitext(os.path.basename(file_name))[0]\n",
    "    try:\n",
    "        sklearn_models[model_name] = load_sklearn_model(file_name)\n",
    "        print(f\"Loaded scikit-learn model: {model_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading scikit-learn model {model_name}: {e}\")\n",
    "\n",
    "# Prepare the results DataFrame\n",
    "results = pd.DataFrame(columns=[\n",
    "    \"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1_Score\", \"AUC_ROC\", \"MSE\", \"MAE\", \"R2\"\n",
    "])\n",
    "\n",
    "# Evaluate scikit-learn models\n",
    "results = evaluate_models(sklearn_models, X_test, y_test, results)\n",
    "\n",
    "# Display results\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h2o\n",
    "from h2o.estimators import H2OEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-7.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-7 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-7 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-7 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-7 .h2o-table th,\n",
       "#h2o-table-7 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-7 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-7\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>57 mins 15 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Kuala_Lumpur</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 29 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Huawei_r97o7a</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.880 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.0 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         57 mins 15 secs\n",
       "H2O_cluster_timezone:       Asia/Kuala_Lumpur\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.6\n",
       "H2O_cluster_version_age:    1 month and 29 days\n",
       "H2O_cluster_name:           H2O_from_python_Huawei_r97o7a\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.880 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.8.0 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialize H2O\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "X_train = pd.read_csv(\"../04_modelling/dataset/X_train.csv\")\n",
    "y_train = pd.read_csv(\"../04_modelling/dataset/y_train.csv\")  # Convert to Series\n",
    "X_test = pd.read_csv(\"../04_modelling/dataset/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../04_modelling/dataset/y_test.csv\")  # Convert to Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1170 entries, 0 to 1169\n",
      "Data columns (total 1 columns):\n",
      " #   Column               Non-Null Count  Dtype\n",
      "---  ------               --------------  -----\n",
      " 0   yearly_compensation  1170 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 9.3 KB\n"
     ]
    }
   ],
   "source": [
    "y_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train, y_train], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "train_h2o = h2o.H2OFrame(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "target = \"yearly_compensation\"\n",
    "features = train_h2o.columns\n",
    "if target in features:\n",
    "    features.remove(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load scikit-learn models\n",
    "def load_sklearn_model(file_name):\n",
    "    with open(file_name, \"rb\") as file:\n",
    "        return joblib.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load H2O models\n",
    "def load_h2o_model(file_name):\n",
    "    return h2o.load_model(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load zipped H2O models (ensemble or similar)\n",
    "def load_zipped_h2o_model(file_name):\n",
    "    with zipfile.ZipFile(file_name, \"r\") as zip_ref:\n",
    "        zip_ref.extractall(\"temp_models\")\n",
    "    extracted_files = os.listdir(\"temp_models\")\n",
    "    model_path = next((os.path.join(\"temp_models\", f) for f in extracted_files if not f.endswith('.zip')), None)\n",
    "    if model_path:\n",
    "        return load_h2o_model(model_path)\n",
    "    raise ValueError(\"No valid model found in the zip file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load models based on file type\n",
    "def load_model(file_name):\n",
    "    if file_name.endswith(\".pkl\"):\n",
    "        return load_sklearn_model(file_name)\n",
    "    elif file_name.endswith(\".zip\"):\n",
    "        return load_zipped_h2o_model(file_name)\n",
    "    else:\n",
    "        return load_h2o_model(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to record evaluation scores\n",
    "def record_scores(model_name, accuracy, precision, recall, f1, auc_roc, results_df):\n",
    "    new_row = pd.DataFrame({\n",
    "        \"Model\": [model_name],\n",
    "        \"Accuracy\": [accuracy],\n",
    "        \"Precision\": [precision],\n",
    "        \"Recall\": [recall],\n",
    "        \"F1-Score\": [f1],\n",
    "        \"AUC-ROC\": [auc_roc]\n",
    "    })\n",
    "    return pd.concat([results_df, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate H2O models\n",
    "def evaluate_h2o_models(models, X_test, y_test, results_df):\n",
    "    h2o_test = h2o.H2OFrame(X_test)  # Convert test data to H2OFrame\n",
    "    for model_name, model in models.items():\n",
    "        try:\n",
    "            if isinstance(model, H2OEstimator):\n",
    "                # Get predictions\n",
    "                predictions_df = model.predict(h2o_test).as_data_frame(use_multi_thread=True)\n",
    "                predictions = predictions_df[\"predict\"]  # Predicted class labels\n",
    "                \n",
    "                # Convert predictions and y_test to compatible formats\n",
    "                predictions = pd.Categorical(predictions)\n",
    "                y_test = pd.Categorical(y_test)\n",
    "                \n",
    "                # Ensure metrics align\n",
    "                accuracy = accuracy_score(y_test, predictions)\n",
    "                precision = precision_score(y_test, predictions, average=\"weighted\")\n",
    "                recall = recall_score(y_test, predictions, average=\"weighted\")\n",
    "                f1 = f1_score(y_test, predictions, average=\"weighted\")\n",
    "                \n",
    "                # Handle probabilities for AUC-ROC\n",
    "                if \"predict\" in predictions_df:\n",
    "                    predictions_proba = predictions_df.drop(columns=[\"predict\"])\n",
    "                    if len(set(y_test)) > 2:  # Multiclass\n",
    "                        auc_roc = roc_auc_score(pd.get_dummies(y_test), predictions_proba, multi_class=\"ovr\")\n",
    "                    else:  # Binary\n",
    "                        auc_roc = roc_auc_score(y_test, predictions_proba.iloc[:, 1])\n",
    "                else:\n",
    "                    auc_roc = None\n",
    "\n",
    "                # Record scores\n",
    "                results_df = record_scores(model_name, accuracy, precision, recall, f1, auc_roc, results_df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating H2O model {model_name}: {e}\")\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: DeepLearning_model_python_1735461052018_31\n",
      "Loaded model: StackedEnsemble_model_python_1735565212779_5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DeepLearning_model_python_1735461052018_31': Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1735461052018_31\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting yearly_compensation, regression, gaussian distribution, Quadratic loss, 10,251 weights/biases, 138.0 KB, 202,094 training samples, mini-batch size 1\n",
       "    layer    units    type    dropout              l1                     l2                      mean_rate           rate_rms             momentum    mean_weight             weight_rms            mean_bias              bias_rms\n",
       "--  -------  -------  ------  -------------------  ---------------------  ----------------------  ------------------  -------------------  ----------  ----------------------  --------------------  ---------------------  -----------------------\n",
       "    1        50       Input   0.13062179562149737\n",
       "    2        50       Maxout  0.0                  0.0008734285704456857  0.00044395405309485716  0.4733223503382411  0.11678057909011841  0.0         -3.979006264033558e-06  0.015364725142717361  0.006642995096825123   0.03519140183925629\n",
       "    3        50       Maxout  0.0                  0.0008734285704456857  0.00044395405309485716  0.4982321396009298  0.04461340606212616  0.0         4.118497943300099e-05   0.018327370285987854  -0.004673484282890519  0.02655043452978134\n",
       "    4        1        Linear                       0.0008734285704456857  0.00044395405309485716  0.4639661560114473  0.13051837682724     0.0         -0.020511514883137353   0.20146846771240234   -0.006056887093238454  1.0971281125650402e-154\n",
       "\n",
       "ModelMetricsRegression: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.06877424596422645\n",
       "RMSE: 0.26224844320648777\n",
       "MAE: 0.1982343550893961\n",
       "RMSLE: 0.09134219559187533\n",
       "Mean Residual Deviance: 0.06877424596422645\n",
       "\n",
       "ModelMetricsRegression: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.07000494825442179\n",
       "RMSE: 0.2645844822630794\n",
       "MAE: 0.20023005208735728\n",
       "RMSLE: NaN\n",
       "Mean Residual Deviance: 0.07000494825442179\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_deviance    training_mae    training_r2    validation_rmse    validation_deviance    validation_mae    validation_r2\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  -------------------  --------------  -------------  -----------------  ---------------------  ----------------  ---------------\n",
       "    2024-12-29 16:54:10  0.000 sec                     0         0             0          nan              nan                  nan             nan            nan                nan                    nan               nan\n",
       "    2024-12-29 16:54:10  0.814 sec   28606 obs/sec     3.69958   1             20196      0.769648         0.592358             0.605059        0.989678       0.868653           0.754557               0.674721          0.986861\n",
       "    2024-12-29 16:54:16  6.369 sec   29398 obs/sec     33.3189   9             181888     0.262248         0.0687742            0.198234        0.998802       0.264584           0.0700049              0.20023           0.998781\n",
       "    2024-12-29 16:54:17  7.141 sec   29374 obs/sec     37.0203   10            202094     0.258666         0.0669081            0.187879        0.998834       0.275944           0.076145               0.196937          0.998674\n",
       "    2024-12-29 16:54:17  7.213 sec   29361 obs/sec     37.0203   10            202094     0.262248         0.0687742            0.198234        0.998802       0.264584           0.0700049              0.20023           0.998781\n",
       "\n",
       "Variable Importances: \n",
       "variable                                           relative_importance    scaled_importance    percentage\n",
       "-------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "used_tpu                                           1.0                    1.0                  0.0249870253298348\n",
       "country_Australia                                  0.9748658537864685     0.9748658537864685   0.02435899778175352\n",
       "company_SUMprofileTable_yearly_compensation        0.9719040989875793     0.9719040989875793   0.024284992339572917\n",
       "country_Ukraine                                    0.9664272665977478     0.9664272665977478   0.024148142589920936\n",
       "country_Taiwan                                     0.9389868974685669     0.9389868974685669   0.023462489391430075\n",
       "job_title_Data_Engineer                            0.937416136264801      0.937416136264801    0.023423240741444456\n",
       "demographics_COUNTprofileTable                     0.9090085029602051     0.9090085029602051   0.022713418488501856\n",
       "PrimaryTool_SUMprofileTable_yearly_compensation    0.8912051916122437     0.8912051916122437   0.02226856669689541\n",
       "country_SUMprofileTable_yearly_compensation        0.8884457349777222     0.8884457349777222   0.02219961608407204\n",
       "company_size                                       0.8597455024719238     0.8597455024719238   0.02148248264747751\n",
       "---                                                ---                    ---                  ---\n",
       "country_Algeria                                    0.7208391427993774     0.7208391427993774   0.01801162591986445\n",
       "job_title_Research_Scientist                       0.7070367336273193     0.7070367336273193   0.01766674477226949\n",
       "country_Portugal                                   0.706606924533844      0.706606924533844    0.017656005121563827\n",
       "country_Switzerland                                0.7058876156806946     0.7058876156806946   0.017638031733030208\n",
       "country_Austria                                    0.6854385733604431     0.6854385733604431   0.01712707099460322\n",
       "job_title_Data_Analyst                             0.6850965619087219     0.6850965619087219   0.01711852514579597\n",
       "demographics_MEANprofileTable_yearly_compensation  0.6841066479682922     0.6841066479682922   0.017093790141092097\n",
       "country_Tunisia                                    0.6809830069541931     0.6809830069541931   0.01701573964395149\n",
       "country_Viet_Nam                                   0.6373131275177002     0.6373131275177002   0.015924559260321013\n",
       "country_COUNTprofileTable                          0.6163108348846436     0.6163108348846436   0.015399774442314223\n",
       "[50 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.,\n",
       " 'StackedEnsemble_model_python_1735565212779_5': Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_model_python_1735565212779_5\n",
       "\n",
       "\n",
       "Model Summary for Stacked Ensemble: \n",
       "key                                   value\n",
       "------------------------------------  ----------------\n",
       "Stacking strategy                     cross_validation\n",
       "Number of base models (used / total)  2/3\n",
       "# GBM base models (used / total)      1/1\n",
       "# DRF base models (used / total)      0/1\n",
       "# GLM base models (used / total)      1/1\n",
       "Metalearner algorithm                 GLM\n",
       "Metalearner fold assignment scheme    AUTO\n",
       "Metalearner nfolds                    0\n",
       "Metalearner fold_column\n",
       "Custom metalearner hyperparameters    None\n",
       "\n",
       "ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.49820427411992424\n",
       "RMSE: 0.705835869108339\n",
       "MAE: 0.5069150933874833\n",
       "RMSLE: NaN\n",
       "Mean Residual Deviance: 0.49820427411992424\n",
       "R^2: 0.9913188484743866\n",
       "Null degrees of freedom: 5458\n",
       "Residual degrees of freedom: 5456\n",
       "Null deviance: 313287.6006594614\n",
       "Residual deviance: 2719.6971324206665\n",
       "AIC: 11696.439420644449\n",
       "\n",
       "ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.5361779611516045\n",
       "RMSE: 0.732241736827125\n",
       "MAE: 0.5364193582193864\n",
       "RMSLE: NaN\n",
       "Mean Residual Deviance: 0.5361779611516045\n",
       "R^2: 0.9906637892775136\n",
       "Null degrees of freedom: 1169\n",
       "Residual degrees of freedom: 1167\n",
       "Null deviance: 67193.0502341876\n",
       "Residual deviance: 627.3282145473773\n",
       "AIC: 2599.0678552457202\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model files\n",
    "model_files = [\n",
    "    \"../04_modelling/models/DeepLearning_model_python_1735461052018_31\",\n",
    "    \"../04_modelling/models/StackedEnsemble_model_python_1735565212779_5\",\n",
    "    # \"../04_modelling/models/voted_ensemble_model.zip\"\n",
    "]\n",
    "\n",
    "# Load models\n",
    "loaded_models = {}\n",
    "for file_name in model_files:\n",
    "    model_name = os.path.splitext(os.path.basename(file_name))[0]\n",
    "    try:\n",
    "        loaded_models[model_name] = load_model(file_name)\n",
    "        print(f\"Loaded model: {model_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model {model_name}: {e}\")\n",
    "loaded_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "items() takes no arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[62], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mloaded_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDeepLearning_model_python_1735461052018_31\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: items() takes no arguments (1 given)"
     ]
    }
   ],
   "source": [
    "loaded_models.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Filter H2O models\n",
    "# h2o_models = {name: model for name, model in loaded_models.items() if isinstance(model, H2OEstimator)}\n",
    "\n",
    "# # Prepare results DataFrame\n",
    "# results = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"AUC-ROC\"])\n",
    "\n",
    "# # Evaluate H2O models\n",
    "# results = evaluate_h2o_models(h2o_models, X_test, y_test_cat, results)\n",
    "\n",
    "# # Display results\n",
    "# results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import h2o\n",
    "import os\n",
    "import zipfile\n",
    "from h2o.estimators.estimator_base import H2OEstimator\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>7 mins 00 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Kuala_Lumpur</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 29 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Huawei_r97o7a</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.952 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.0 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         7 mins 00 secs\n",
       "H2O_cluster_timezone:       Asia/Kuala_Lumpur\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.6\n",
       "H2O_cluster_version_age:    1 month and 29 days\n",
       "H2O_cluster_name:           H2O_from_python_Huawei_r97o7a\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.952 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.8.0 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Start the H2O server for AutoML models\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading model catboost_grid_search: DLL load failed while importing _catboost: Not enough memory resources are available to process this command.\n",
      "Loaded model: DeepLearning_model_python_1735461052018_31\n",
      "Loaded model: dtree_model\n",
      "Loaded model: mlp_neural_net\n",
      "Loaded model: random_forest_model\n",
      "Loaded model: StackedEnsemble_model_python_1735565212779_5\n",
      "Loaded model: voted_ensemble_model\n"
     ]
    }
   ],
   "source": [
    "# Initialize dictionary to store loaded models\n",
    "loaded_models = {}\n",
    "\n",
    "# Define model files\n",
    "model_files = [\n",
    "    \"../04_modelling/models/catboost_grid_search.pkl\",\n",
    "    \"../04_modelling/models/DeepLearning_model_python_1735461052018_31\",\n",
    "    \"../04_modelling/models/dtree_model.pkl\",\n",
    "    \"../04_modelling/models/mlp_neural_net.pkl\",\n",
    "    \"../04_modelling/models/random_forest_model.pkl\",\n",
    "    \"../04_modelling/models/StackedEnsemble_model_python_1735565212779_5\",\n",
    "    \"../04_modelling/models/voted_ensemble_model.zip\"\n",
    "]\n",
    "\n",
    "# Function to load scikit-learn models\n",
    "def load_sklearn_model(file_name):\n",
    "    with open(file_name, \"rb\") as file:\n",
    "        return joblib.load(file)\n",
    "\n",
    "# Function to load H2O models\n",
    "def load_h2o_model(file_name):\n",
    "    return h2o.load_model(file_name)\n",
    "\n",
    "# Function to load a model based on its file type\n",
    "def load_model(file_name):\n",
    "    if file_name.endswith(\".pkl\"):\n",
    "        return load_sklearn_model(file_name)\n",
    "    elif file_name.endswith(\".zip\"):\n",
    "        # Assuming zip contains a model file\n",
    "        with zipfile.ZipFile(file_name, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(\"temp_models\")\n",
    "        # Add specific logic for ensemble models here if necessary\n",
    "        return None  # Placeholder\n",
    "    else:\n",
    "        return load_h2o_model(file_name)\n",
    "\n",
    "# Load all models\n",
    "for file_name in model_files:\n",
    "    model_name = os.path.splitext(os.path.basename(file_name))[0]\n",
    "    try:\n",
    "        loaded_models[model_name] = load_model(file_name)\n",
    "        print(f\"Loaded model: {model_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DeepLearning_model_python_1735461052018_31': Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1735461052018_31\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting yearly_compensation, regression, gaussian distribution, Quadratic loss, 10,251 weights/biases, 138.0 KB, 202,094 training samples, mini-batch size 1\n",
       "    layer    units    type    dropout              l1                     l2                      mean_rate           rate_rms             momentum    mean_weight             weight_rms            mean_bias              bias_rms\n",
       "--  -------  -------  ------  -------------------  ---------------------  ----------------------  ------------------  -------------------  ----------  ----------------------  --------------------  ---------------------  -----------------------\n",
       "    1        50       Input   0.13062179562149737\n",
       "    2        50       Maxout  0.0                  0.0008734285704456857  0.00044395405309485716  0.4733223503382411  0.11678057909011841  0.0         -3.979006264033558e-06  0.015364725142717361  0.006642995096825123   0.03519140183925629\n",
       "    3        50       Maxout  0.0                  0.0008734285704456857  0.00044395405309485716  0.4982321396009298  0.04461340606212616  0.0         4.118497943300099e-05   0.018327370285987854  -0.004673484282890519  0.02655043452978134\n",
       "    4        1        Linear                       0.0008734285704456857  0.00044395405309485716  0.4639661560114473  0.13051837682724     0.0         -0.020511514883137353   0.20146846771240234   -0.006056887093238454  1.0971281125650402e-154\n",
       "\n",
       "ModelMetricsRegression: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.06877424596422645\n",
       "RMSE: 0.26224844320648777\n",
       "MAE: 0.1982343550893961\n",
       "RMSLE: 0.09134219559187533\n",
       "Mean Residual Deviance: 0.06877424596422645\n",
       "\n",
       "ModelMetricsRegression: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.07000494825442179\n",
       "RMSE: 0.2645844822630794\n",
       "MAE: 0.20023005208735728\n",
       "RMSLE: NaN\n",
       "Mean Residual Deviance: 0.07000494825442179\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_deviance    training_mae    training_r2    validation_rmse    validation_deviance    validation_mae    validation_r2\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  -------------------  --------------  -------------  -----------------  ---------------------  ----------------  ---------------\n",
       "    2024-12-29 16:54:10  0.000 sec                     0         0             0          nan              nan                  nan             nan            nan                nan                    nan               nan\n",
       "    2024-12-29 16:54:10  0.814 sec   28606 obs/sec     3.69958   1             20196      0.769648         0.592358             0.605059        0.989678       0.868653           0.754557               0.674721          0.986861\n",
       "    2024-12-29 16:54:16  6.369 sec   29398 obs/sec     33.3189   9             181888     0.262248         0.0687742            0.198234        0.998802       0.264584           0.0700049              0.20023           0.998781\n",
       "    2024-12-29 16:54:17  7.141 sec   29374 obs/sec     37.0203   10            202094     0.258666         0.0669081            0.187879        0.998834       0.275944           0.076145               0.196937          0.998674\n",
       "    2024-12-29 16:54:17  7.213 sec   29361 obs/sec     37.0203   10            202094     0.262248         0.0687742            0.198234        0.998802       0.264584           0.0700049              0.20023           0.998781\n",
       "\n",
       "Variable Importances: \n",
       "variable                                           relative_importance    scaled_importance    percentage\n",
       "-------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "used_tpu                                           1.0                    1.0                  0.0249870253298348\n",
       "country_Australia                                  0.9748658537864685     0.9748658537864685   0.02435899778175352\n",
       "company_SUMprofileTable_yearly_compensation        0.9719040989875793     0.9719040989875793   0.024284992339572917\n",
       "country_Ukraine                                    0.9664272665977478     0.9664272665977478   0.024148142589920936\n",
       "country_Taiwan                                     0.9389868974685669     0.9389868974685669   0.023462489391430075\n",
       "job_title_Data_Engineer                            0.937416136264801      0.937416136264801    0.023423240741444456\n",
       "demographics_COUNTprofileTable                     0.9090085029602051     0.9090085029602051   0.022713418488501856\n",
       "PrimaryTool_SUMprofileTable_yearly_compensation    0.8912051916122437     0.8912051916122437   0.02226856669689541\n",
       "country_SUMprofileTable_yearly_compensation        0.8884457349777222     0.8884457349777222   0.02219961608407204\n",
       "company_size                                       0.8597455024719238     0.8597455024719238   0.02148248264747751\n",
       "---                                                ---                    ---                  ---\n",
       "country_Algeria                                    0.7208391427993774     0.7208391427993774   0.01801162591986445\n",
       "job_title_Research_Scientist                       0.7070367336273193     0.7070367336273193   0.01766674477226949\n",
       "country_Portugal                                   0.706606924533844      0.706606924533844    0.017656005121563827\n",
       "country_Switzerland                                0.7058876156806946     0.7058876156806946   0.017638031733030208\n",
       "country_Austria                                    0.6854385733604431     0.6854385733604431   0.01712707099460322\n",
       "job_title_Data_Analyst                             0.6850965619087219     0.6850965619087219   0.01711852514579597\n",
       "demographics_MEANprofileTable_yearly_compensation  0.6841066479682922     0.6841066479682922   0.017093790141092097\n",
       "country_Tunisia                                    0.6809830069541931     0.6809830069541931   0.01701573964395149\n",
       "country_Viet_Nam                                   0.6373131275177002     0.6373131275177002   0.015924559260321013\n",
       "country_COUNTprofileTable                          0.6163108348846436     0.6163108348846436   0.015399774442314223\n",
       "[50 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.,\n",
       " 'dtree_model': BaggingClassifier(bootstrap=False,\n",
       "                   estimator=DecisionTreeClassifier(criterion='entropy',\n",
       "                                                    max_depth=16,\n",
       "                                                    min_samples_leaf=4,\n",
       "                                                    min_samples_split=9,\n",
       "                                                    random_state=123),\n",
       "                   max_features=0.6986074415599616,\n",
       "                   max_samples=0.7080360245310086, n_estimators=74,\n",
       "                   random_state=123),\n",
       " 'mlp_neural_net': MLPClassifier(activation='identity', alpha=0.0002712909526978834,\n",
       "               hidden_layer_sizes=(50, 50), learning_rate='adaptive',\n",
       "               max_iter=500, random_state=123, solver='lbfgs'),\n",
       " 'random_forest_model': RandomForestRegressor(max_features=None, min_samples_leaf=2, n_estimators=500,\n",
       "                       random_state=42),\n",
       " 'StackedEnsemble_model_python_1735565212779_5': Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_model_python_1735565212779_5\n",
       "\n",
       "\n",
       "Model Summary for Stacked Ensemble: \n",
       "key                                   value\n",
       "------------------------------------  ----------------\n",
       "Stacking strategy                     cross_validation\n",
       "Number of base models (used / total)  2/3\n",
       "# GBM base models (used / total)      1/1\n",
       "# DRF base models (used / total)      0/1\n",
       "# GLM base models (used / total)      1/1\n",
       "Metalearner algorithm                 GLM\n",
       "Metalearner fold assignment scheme    AUTO\n",
       "Metalearner nfolds                    0\n",
       "Metalearner fold_column\n",
       "Custom metalearner hyperparameters    None\n",
       "\n",
       "ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.49820427411992424\n",
       "RMSE: 0.705835869108339\n",
       "MAE: 0.5069150933874833\n",
       "RMSLE: NaN\n",
       "Mean Residual Deviance: 0.49820427411992424\n",
       "R^2: 0.9913188484743866\n",
       "Null degrees of freedom: 5458\n",
       "Residual degrees of freedom: 5456\n",
       "Null deviance: 313287.6006594614\n",
       "Residual deviance: 2719.6971324206665\n",
       "AIC: 11696.439420644449\n",
       "\n",
       "ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.5361779611516045\n",
       "RMSE: 0.732241736827125\n",
       "MAE: 0.5364193582193864\n",
       "RMSLE: NaN\n",
       "Mean Residual Deviance: 0.5361779611516045\n",
       "R^2: 0.9906637892775136\n",
       "Null degrees of freedom: 1169\n",
       "Residual degrees of freedom: 1167\n",
       "Null deviance: 67193.0502341876\n",
       "Residual deviance: 627.3282145473773\n",
       "AIC: 2599.0678552457202\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.,\n",
       " 'voted_ensemble_model': None}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "X_train = pd.read_csv(\"../04_modelling/dataset/X_train.csv\")\n",
    "y_train = pd.read_csv(\"../04_modelling/dataset/y_train.csv\").squeeze()  # Convert to Series if needed\n",
    "X_test = pd.read_csv(\"../04_modelling/dataset/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../04_modelling/dataset/y_test.csv\").squeeze()    # Convert to Series if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Function to record evaluation scores\n",
    "def record_scores(model_name, accuracy, precision, recall, f1, auc_roc, results_df):\n",
    "    \"\"\"\n",
    "    Append evaluation scores to the results DataFrame using pd.concat.\n",
    "    \"\"\"\n",
    "    new_row = pd.DataFrame({\n",
    "        \"Model\": [model_name],\n",
    "        \"Accuracy\": [accuracy],\n",
    "        \"Precision\": [precision],\n",
    "        \"Recall\": [recall],\n",
    "        \"F1-Score\": [f1],\n",
    "        \"AUC-ROC\": [auc_roc]\n",
    "    })\n",
    "    results_df = pd.concat([results_df, new_row], ignore_index=True)\n",
    "    return results_df\n",
    "\n",
    "# Function to evaluate scikit-learn models\n",
    "def evaluate_sklearn_models(models, X_test, y_test, results_df):\n",
    "    \"\"\"\n",
    "    Evaluate scikit-learn models.\n",
    "    \"\"\"\n",
    "    for model_name, model in models.items():\n",
    "        try:\n",
    "            predictions = model.predict(X_test)\n",
    "            predictions_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "            accuracy = accuracy_score(y_test, predictions)\n",
    "            precision = precision_score(y_test, predictions, average=\"weighted\")\n",
    "            recall = recall_score(y_test, predictions, average=\"weighted\")\n",
    "            f1 = f1_score(y_test, predictions, average=\"weighted\")\n",
    "            \n",
    "            # Handle AUC-ROC for multiclass\n",
    "            if predictions_proba is not None and len(set(y_test)) > 2:\n",
    "                auc_roc = roc_auc_score(pd.get_dummies(y_test), predictions_proba, multi_class=\"ovr\")\n",
    "            elif predictions_proba is not None:\n",
    "                auc_roc = roc_auc_score(y_test, predictions_proba[:, 1])\n",
    "            else:\n",
    "                auc_roc = None\n",
    "\n",
    "            results_df = record_scores(model_name, accuracy, precision, recall, f1, auc_roc, results_df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating scikit-learn model {model_name}: {e}\")\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate scikit-learn models\n",
    "def evaluate_sklearn_models(models, X_test, y_test, results_df):\n",
    "    \"\"\"\n",
    "    Evaluate scikit-learn models.\n",
    "    \"\"\"\n",
    "    for model_name, model in models.items():\n",
    "        try:\n",
    "            predictions = model.predict(X_test)\n",
    "            predictions_proba = model.predict_proba(X_test) if hasattr(model, \"predict_proba\") else None\n",
    "\n",
    "            accuracy = accuracy_score(y_test, predictions)\n",
    "            precision = precision_score(y_test, predictions, average=\"weighted\")\n",
    "            recall = recall_score(y_test, predictions, average=\"weighted\")\n",
    "            f1 = f1_score(y_test, predictions, average=\"weighted\")\n",
    "            auc_roc = (\n",
    "                roc_auc_score(y_test, predictions_proba, multi_class=\"ovr\") if predictions_proba is not None else None\n",
    "            )\n",
    "\n",
    "            results_df = record_scores(model_name, accuracy, precision, recall, f1, auc_roc, results_df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating scikit-learn model {model_name}: {e}\")\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h2o\n",
    "from h2o.estimators import H2OEstimator\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "\n",
    "# Function to evaluate H2O models\n",
    "def evaluate_h2o_models(models, X_test, y_test, results_df):\n",
    "    \"\"\"\n",
    "    Evaluate H2O models.\n",
    "    \"\"\"\n",
    "    h2o_test = h2o.H2OFrame(X_test)  # Convert test data to H2OFrame\n",
    "    for model_name, model in models.items():\n",
    "        try:\n",
    "            if isinstance(model, H2OEstimator):\n",
    "                # Get predictions\n",
    "                predictions_df = model.predict(h2o_test).as_data_frame(use_multi_thread=True)\n",
    "                predictions = predictions_df[\"predict\"]  # Predicted classes\n",
    "\n",
    "                # Check for probabilities if needed\n",
    "                predictions_proba = predictions_df.drop(columns=[\"predict\"], errors=\"ignore\") if \"predict\" in predictions_df else None\n",
    "\n",
    "                # Ensure `y_test` is categorical if predictions are categorical\n",
    "                y_test = pd.Categorical(y_test) if isinstance(y_test, pd.Series) else y_test\n",
    "\n",
    "                # Calculate metrics\n",
    "                accuracy = accuracy_score(y_test, predictions)\n",
    "                precision = precision_score(y_test, predictions, average=\"weighted\")\n",
    "                recall = recall_score(y_test, predictions, average=\"weighted\")\n",
    "                f1 = f1_score(y_test, predictions, average=\"weighted\")\n",
    "\n",
    "                # Handle AUC-ROC for binary or multiclass\n",
    "                if predictions_proba is not None:\n",
    "                    if len(set(y_test)) > 2:  # Multiclass\n",
    "                        auc_roc = roc_auc_score(pd.get_dummies(y_test), predictions_proba, multi_class=\"ovr\")\n",
    "                    else:  # Binary\n",
    "                        auc_roc = roc_auc_score(y_test, predictions_proba.iloc[:, 1])\n",
    "                else:\n",
    "                    auc_roc = None\n",
    "\n",
    "                # Record scores\n",
    "                results_df = record_scores(model_name, accuracy, precision, recall, f1, auc_roc, results_df)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error evaluating H2O model {model_name}: {e}\")\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate models into scikit-learn and H2O categories\n",
    "sklearn_models = {\n",
    "    name: model for name, model in loaded_models.items() if not isinstance(model, H2OEstimator)\n",
    "}\n",
    "h2o_models = {\n",
    "    name: model for name, model in loaded_models.items() if isinstance(model, H2OEstimator)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dtree_model': BaggingClassifier(bootstrap=False,\n",
       "                   estimator=DecisionTreeClassifier(criterion='entropy',\n",
       "                                                    max_depth=16,\n",
       "                                                    min_samples_leaf=4,\n",
       "                                                    min_samples_split=9,\n",
       "                                                    random_state=123),\n",
       "                   max_features=0.6986074415599616,\n",
       "                   max_samples=0.7080360245310086, n_estimators=74,\n",
       "                   random_state=123),\n",
       " 'mlp_neural_net': MLPClassifier(activation='identity', alpha=0.0002712909526978834,\n",
       "               hidden_layer_sizes=(50, 50), learning_rate='adaptive',\n",
       "               max_iter=500, random_state=123, solver='lbfgs'),\n",
       " 'random_forest_model': RandomForestRegressor(max_features=None, min_samples_leaf=2, n_estimators=500,\n",
       "                       random_state=42),\n",
       " 'voted_ensemble_model': None}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the results DataFrame\n",
    "results = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-Score\", \"AUC-ROC\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error evaluating scikit-learn model random_forest_model: Classification metrics can't handle a mix of multiclass and continuous targets\n",
      "Error evaluating scikit-learn model voted_ensemble_model: 'NoneType' object has no attribute 'predict'\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_sklearn_models(sklearn_models, X_test, y_test, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "Export File progress: |██████████████████████████████████████████████████████████| (done) 100%\n",
      "Error evaluating H2O model DeepLearning_model_python_1735461052018_31: Classification metrics can't handle a mix of multiclass and continuous targets\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n",
      "Export File progress: |██████████████████████████████████████████████████████████| (done) 100%\n",
      "Error evaluating H2O model StackedEnsemble_model_python_1735565212779_5: Classification metrics can't handle a mix of multiclass and continuous targets\n"
     ]
    }
   ],
   "source": [
    "results = evaluate_h2o_models(h2o_models, X_test, y_test, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dtree_model</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.543476</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.538275</td>\n",
       "      <td>0.955129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mlp_neural_net</td>\n",
       "      <td>0.898291</td>\n",
       "      <td>0.898978</td>\n",
       "      <td>0.898291</td>\n",
       "      <td>0.897737</td>\n",
       "      <td>0.996135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Accuracy  Precision    Recall  F1-Score   AUC-ROC\n",
       "0     dtree_model  0.555556   0.543476  0.555556  0.538275  0.955129\n",
       "1  mlp_neural_net  0.898291   0.898978  0.898291  0.897737  0.996135"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321..... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; OpenJDK 64-Bit Server VM Temurin-17.0.12+7 (build 17.0.12+7, mixed mode, sharing)\n",
      "  Starting server from C:\\Users\\Huawei\\OneDrive - Universiti Malaya\\Desktop\\SEMESTER 7\\WIE3007_Data-Mining\\Group Project\\data-mining-warehousing-wages-analysis\\venv\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\Huawei\\AppData\\Local\\Temp\\tmp58f_ikfo\n",
      "  JVM stdout: C:\\Users\\Huawei\\AppData\\Local\\Temp\\tmp58f_ikfo\\h2o_Huawei_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\Huawei\\AppData\\Local\\Temp\\tmp58f_ikfo\\h2o_Huawei_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-1.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-1 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-1 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-1 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-1 .h2o-table th,\n",
       "#h2o-table-1 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-1 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-1\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>05 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Kuala_Lumpur</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 30 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Huawei_5wops1</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.961 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.0 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         05 secs\n",
       "H2O_cluster_timezone:       Asia/Kuala_Lumpur\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.6\n",
       "H2O_cluster_version_age:    1 month and 30 days\n",
       "H2O_cluster_name:           H2O_from_python_Huawei_5wops1\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.961 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.8.0 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "deeplearning Model Build progress: |█████████████████████████████████████████████| (done) 100%\n",
      "Training Performance:\n",
      "ModelMetricsRegression: deeplearning\n",
      "** Reported on train data. **\n",
      "\n",
      "MSE: 0.11935238463856258\n",
      "RMSE: 0.3454741446744786\n",
      "MAE: 0.2704941605232003\n",
      "RMSLE: 0.10651841963076515\n",
      "Mean Residual Deviance: 0.11935238463856258\n",
      "\n",
      "Test Performance:\n",
      "ModelMetricsRegression: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.19339239352761498\n",
      "RMSE: 0.43976402027407263\n",
      "MAE: 0.33467287406073365\n",
      "RMSLE: 0.12822266355020856\n",
      "Mean Residual Deviance: 0.19339239352761498\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n",
      "\n",
      "Additional Evaluation Metrics:\n",
      "MSE: 0.19339239352761528\n",
      "RMSE: 0.43976402027407296\n",
      "MAE: 0.334672874060734\n",
      "R^2 Score: 0.996628950635985\n",
      "Model saved to: C:\\Users\\Huawei\\OneDrive - Universiti Malaya\\Desktop\\SEMESTER 7\\WIE3007_Data-Mining\\Group Project\\data-mining-warehousing-wages-analysis\\notebooks\\04_modelling\\models\\DeepLearning_model_python_1735700786303_1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huawei\\OneDrive - Universiti Malaya\\Desktop\\SEMESTER 7\\WIE3007_Data-Mining\\Group Project\\data-mining-warehousing-wages-analysis\\venv\\lib\\site-packages\\h2o\\frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import h2o\n",
    "from h2o.estimators import H2ODeepLearningEstimator\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize H2O\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to store loaded models\n",
    "loaded_models = {}\n",
    "\n",
    "# Define model files\n",
    "model_files = [\n",
    "    \"../04_modelling/models/catboost_grid_search.pkl\",\n",
    "    \"../04_modelling/models/DeepLearning_model_python_1735461052018_31\",\n",
    "    \"../04_modelling/models/dtree_model.pkl\",\n",
    "    \"../04_modelling/models/mlp_neural_net.pkl\",\n",
    "    \"../04_modelling/models/random_forest_model.pkl\",\n",
    "    \"../04_modelling/models/StackedEnsemble_model_python_1735565212779_5\",\n",
    "    \"../04_modelling/models/voted_ensemble_model.zip\"\n",
    "]\n",
    "\n",
    "# Function to load scikit-learn models\n",
    "def load_sklearn_model(file_name):\n",
    "    with open(file_name, \"rb\") as file:\n",
    "        return joblib.load(file)\n",
    "\n",
    "# Function to load H2O models\n",
    "def load_h2o_model(file_name):\n",
    "    return h2o.load_model(file_name)\n",
    "\n",
    "# Function to load a model based on its file type\n",
    "def load_model(file_name):\n",
    "    if file_name.endswith(\".pkl\"):\n",
    "        return load_sklearn_model(file_name)\n",
    "    elif file_name.endswith(\".zip\"):\n",
    "        # Assuming zip contains a model file\n",
    "        with zipfile.ZipFile(file_name, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(\"temp_models\")\n",
    "        # Add specific logic for ensemble models here if necessary\n",
    "        return None  # Placeholder\n",
    "    else:\n",
    "        return load_h2o_model(file_name)\n",
    "\n",
    "# Load all models\n",
    "for file_name in model_files:\n",
    "    model_name = os.path.splitext(os.path.basename(file_name))[0]\n",
    "    try:\n",
    "        loaded_models[model_name] = load_model(file_name)\n",
    "        print(f\"Loaded model: {model_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "X_train = pd.read_csv(\"../04_modelling/dataset/X_train.csv\")\n",
    "y_train = pd.read_csv(\"../04_modelling/dataset/y_train.csv\")  # Ensure this is a DataFrame or Series\n",
    "X_test = pd.read_csv(\"../04_modelling/dataset/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../04_modelling/dataset/y_test.csv\")  # Ensure this is a DataFrame or Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine X_train and y_train into one DataFrame for H2OFrame\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "train_h2o = h2o.H2OFrame(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine X_test and y_test into one DataFrame for H2OFrame\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "test_h2o = h2o.H2OFrame(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target and features\n",
    "target = y_train.columns[0]  # Assuming the target column name is present in y_train\n",
    "features = X_train.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "def evaluate_model(model, train_h2o, test_h2o, y_test):\n",
    "    # Training performance\n",
    "    train_performance = model.model_performance(train=True)\n",
    "    print(\"Training Performance:\")\n",
    "    print(train_performance)\n",
    "\n",
    "    # Validation performance\n",
    "    test_performance = model.model_performance(test_data=test_h2o)\n",
    "    print(\"\\nTest Performance:\")\n",
    "    print(test_performance)\n",
    "\n",
    "    # Extracting predictions\n",
    "    predictions = model.predict(test_h2o).as_data_frame().values.flatten()\n",
    "\n",
    "    # Calculate additional metrics using sklearn\n",
    "    mse = mean_squared_error(y_test, predictions)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, predictions)\n",
    "    r2 = r2_score(y_test, predictions)\n",
    "\n",
    "    print(\"\\nAdditional Evaluation Metrics:\")\n",
    "    print(f\"MSE: {mse}\")\n",
    "    print(f\"RMSE: {rmse}\")\n",
    "    print(f\"MAE: {mae}\")\n",
    "    print(f\"R^2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the evaluation function\n",
    "evaluate_model(loaded_models, train_h2o, test_h2o, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321. connected.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>16 mins 01 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Asia/Kuala_Lumpur</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.46.0.6</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 30 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_Huawei_5wops1</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>1.884 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://localhost:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.8.0 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  -----------------------------\n",
       "H2O_cluster_uptime:         16 mins 01 secs\n",
       "H2O_cluster_timezone:       Asia/Kuala_Lumpur\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.46.0.6\n",
       "H2O_cluster_version_age:    1 month and 30 days\n",
       "H2O_cluster_name:           H2O_from_python_Huawei_5wops1\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    1.884 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  8\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://localhost:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.8.0 final\n",
       "--------------------------  -----------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "import h2o\n",
    "from h2o.estimators import H2ODeepLearningEstimator\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Initialize H2O\n",
    "h2o.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionary to store loaded models\n",
    "loaded_models = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model files\n",
    "model_files = [\n",
    "    \"../04_modelling/models/DeepLearning_model_python_1735461052018_31\",\n",
    "    \"../04_modelling/models/StackedEnsemble_model_python_1735565212779_5\",\n",
    "    # \"../04_modelling/models/voted_ensemble_model.zip\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load H2O models\n",
    "def load_h2o_model(file_name):\n",
    "    return h2o.load_model(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load a model based on its file type\n",
    "def load_model(file_name):\n",
    "    if file_name.endswith(\".pkl\"):\n",
    "        return load_sklearn_model(file_name)\n",
    "    elif file_name.endswith(\".zip\"):\n",
    "        # Assuming zip contains a model file\n",
    "        with zipfile.ZipFile(file_name, \"r\") as zip_ref:\n",
    "            zip_ref.extractall(\"temp_models\")\n",
    "        # Add specific logic for ensemble models here if necessary\n",
    "        return None  # Placeholder\n",
    "    else:\n",
    "        return load_h2o_model(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: DeepLearning_model_python_1735461052018_31\n",
      "Loaded model: StackedEnsemble_model_python_1735565212779_5\n"
     ]
    }
   ],
   "source": [
    "# Load all models\n",
    "for file_name in model_files:\n",
    "    model_name = os.path.splitext(os.path.basename(file_name))[0]\n",
    "    try:\n",
    "        loaded_models[model_name] = load_model(file_name)\n",
    "        print(f\"Loaded model: {model_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading model {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DeepLearning_model_python_1735461052018_31': Model Details\n",
       "=============\n",
       "H2ODeepLearningEstimator : Deep Learning\n",
       "Model Key: DeepLearning_model_python_1735461052018_31\n",
       "\n",
       "\n",
       "Status of Neuron Layers: predicting yearly_compensation, regression, gaussian distribution, Quadratic loss, 10,251 weights/biases, 138.0 KB, 202,094 training samples, mini-batch size 1\n",
       "    layer    units    type    dropout              l1                     l2                      mean_rate           rate_rms             momentum    mean_weight             weight_rms            mean_bias              bias_rms\n",
       "--  -------  -------  ------  -------------------  ---------------------  ----------------------  ------------------  -------------------  ----------  ----------------------  --------------------  ---------------------  -----------------------\n",
       "    1        50       Input   0.13062179562149737\n",
       "    2        50       Maxout  0.0                  0.0008734285704456857  0.00044395405309485716  0.4733223503382411  0.11678057909011841  0.0         -3.979006264033558e-06  0.015364725142717361  0.006642995096825123   0.03519140183925629\n",
       "    3        50       Maxout  0.0                  0.0008734285704456857  0.00044395405309485716  0.4982321396009298  0.04461340606212616  0.0         4.118497943300099e-05   0.018327370285987854  -0.004673484282890519  0.02655043452978134\n",
       "    4        1        Linear                       0.0008734285704456857  0.00044395405309485716  0.4639661560114473  0.13051837682724     0.0         -0.020511514883137353   0.20146846771240234   -0.006056887093238454  1.0971281125650402e-154\n",
       "\n",
       "ModelMetricsRegression: deeplearning\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.06877424596422645\n",
       "RMSE: 0.26224844320648777\n",
       "MAE: 0.1982343550893961\n",
       "RMSLE: 0.09134219559187533\n",
       "Mean Residual Deviance: 0.06877424596422645\n",
       "\n",
       "ModelMetricsRegression: deeplearning\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.07000494825442179\n",
       "RMSE: 0.2645844822630794\n",
       "MAE: 0.20023005208735728\n",
       "RMSLE: NaN\n",
       "Mean Residual Deviance: 0.07000494825442179\n",
       "\n",
       "Scoring History: \n",
       "    timestamp            duration    training_speed    epochs    iterations    samples    training_rmse    training_deviance    training_mae    training_r2    validation_rmse    validation_deviance    validation_mae    validation_r2\n",
       "--  -------------------  ----------  ----------------  --------  ------------  ---------  ---------------  -------------------  --------------  -------------  -----------------  ---------------------  ----------------  ---------------\n",
       "    2024-12-29 16:54:10  0.000 sec                     0         0             0          nan              nan                  nan             nan            nan                nan                    nan               nan\n",
       "    2024-12-29 16:54:10  0.814 sec   28606 obs/sec     3.69958   1             20196      0.769648         0.592358             0.605059        0.989678       0.868653           0.754557               0.674721          0.986861\n",
       "    2024-12-29 16:54:16  6.369 sec   29398 obs/sec     33.3189   9             181888     0.262248         0.0687742            0.198234        0.998802       0.264584           0.0700049              0.20023           0.998781\n",
       "    2024-12-29 16:54:17  7.141 sec   29374 obs/sec     37.0203   10            202094     0.258666         0.0669081            0.187879        0.998834       0.275944           0.076145               0.196937          0.998674\n",
       "    2024-12-29 16:54:17  7.213 sec   29361 obs/sec     37.0203   10            202094     0.262248         0.0687742            0.198234        0.998802       0.264584           0.0700049              0.20023           0.998781\n",
       "\n",
       "Variable Importances: \n",
       "variable                                           relative_importance    scaled_importance    percentage\n",
       "-------------------------------------------------  ---------------------  -------------------  --------------------\n",
       "used_tpu                                           1.0                    1.0                  0.0249870253298348\n",
       "country_Australia                                  0.9748658537864685     0.9748658537864685   0.02435899778175352\n",
       "company_SUMprofileTable_yearly_compensation        0.9719040989875793     0.9719040989875793   0.024284992339572917\n",
       "country_Ukraine                                    0.9664272665977478     0.9664272665977478   0.024148142589920936\n",
       "country_Taiwan                                     0.9389868974685669     0.9389868974685669   0.023462489391430075\n",
       "job_title_Data_Engineer                            0.937416136264801      0.937416136264801    0.023423240741444456\n",
       "demographics_COUNTprofileTable                     0.9090085029602051     0.9090085029602051   0.022713418488501856\n",
       "PrimaryTool_SUMprofileTable_yearly_compensation    0.8912051916122437     0.8912051916122437   0.02226856669689541\n",
       "country_SUMprofileTable_yearly_compensation        0.8884457349777222     0.8884457349777222   0.02219961608407204\n",
       "company_size                                       0.8597455024719238     0.8597455024719238   0.02148248264747751\n",
       "---                                                ---                    ---                  ---\n",
       "country_Algeria                                    0.7208391427993774     0.7208391427993774   0.01801162591986445\n",
       "job_title_Research_Scientist                       0.7070367336273193     0.7070367336273193   0.01766674477226949\n",
       "country_Portugal                                   0.706606924533844      0.706606924533844    0.017656005121563827\n",
       "country_Switzerland                                0.7058876156806946     0.7058876156806946   0.017638031733030208\n",
       "country_Austria                                    0.6854385733604431     0.6854385733604431   0.01712707099460322\n",
       "job_title_Data_Analyst                             0.6850965619087219     0.6850965619087219   0.01711852514579597\n",
       "demographics_MEANprofileTable_yearly_compensation  0.6841066479682922     0.6841066479682922   0.017093790141092097\n",
       "country_Tunisia                                    0.6809830069541931     0.6809830069541931   0.01701573964395149\n",
       "country_Viet_Nam                                   0.6373131275177002     0.6373131275177002   0.015924559260321013\n",
       "country_COUNTprofileTable                          0.6163108348846436     0.6163108348846436   0.015399774442314223\n",
       "[50 rows x 4 columns]\n",
       "\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.,\n",
       " 'StackedEnsemble_model_python_1735565212779_5': Model Details\n",
       "=============\n",
       "H2OStackedEnsembleEstimator : Stacked Ensemble\n",
       "Model Key: StackedEnsemble_model_python_1735565212779_5\n",
       "\n",
       "\n",
       "Model Summary for Stacked Ensemble: \n",
       "key                                   value\n",
       "------------------------------------  ----------------\n",
       "Stacking strategy                     cross_validation\n",
       "Number of base models (used / total)  2/3\n",
       "# GBM base models (used / total)      1/1\n",
       "# DRF base models (used / total)      0/1\n",
       "# GLM base models (used / total)      1/1\n",
       "Metalearner algorithm                 GLM\n",
       "Metalearner fold assignment scheme    AUTO\n",
       "Metalearner nfolds                    0\n",
       "Metalearner fold_column\n",
       "Custom metalearner hyperparameters    None\n",
       "\n",
       "ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on train data. **\n",
       "\n",
       "MSE: 0.49820427411992424\n",
       "RMSE: 0.705835869108339\n",
       "MAE: 0.5069150933874833\n",
       "RMSLE: NaN\n",
       "Mean Residual Deviance: 0.49820427411992424\n",
       "R^2: 0.9913188484743866\n",
       "Null degrees of freedom: 5458\n",
       "Residual degrees of freedom: 5456\n",
       "Null deviance: 313287.6006594614\n",
       "Residual deviance: 2719.6971324206665\n",
       "AIC: 11696.439420644449\n",
       "\n",
       "ModelMetricsRegressionGLM: stackedensemble\n",
       "** Reported on validation data. **\n",
       "\n",
       "MSE: 0.5361779611516045\n",
       "RMSE: 0.732241736827125\n",
       "MAE: 0.5364193582193864\n",
       "RMSLE: NaN\n",
       "Mean Residual Deviance: 0.5361779611516045\n",
       "R^2: 0.9906637892775136\n",
       "Null degrees of freedom: 1169\n",
       "Residual degrees of freedom: 1167\n",
       "Null deviance: 67193.0502341876\n",
       "Residual deviance: 627.3282145473773\n",
       "AIC: 2599.0678552457202\n",
       "\n",
       "[tips]\n",
       "Use `model.explain()` to inspect the model.\n",
       "--\n",
       "Use `h2o.display.toggle_user_tips()` to switch on/off this section.}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "X_train = pd.read_csv(\"../04_modelling/dataset/X_train.csv\")\n",
    "y_train = pd.read_csv(\"../04_modelling/dataset/y_train.csv\")  # Ensure this is a DataFrame or Series\n",
    "X_test = pd.read_csv(\"../04_modelling/dataset/X_test.csv\")\n",
    "y_test = pd.read_csv(\"../04_modelling/dataset/y_test.csv\")  # Ensure this is a DataFrame or Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n"
     ]
    }
   ],
   "source": [
    "# Combine X_test and y_test into one DataFrame for H2OFrame\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "test_h2o = h2o.H2OFrame(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a DataFrame to store model evaluation results\n",
    "results = pd.DataFrame(columns=[\"Model\", \"MSE\", \"RMSE\", \"MAE\", \"R2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model and record performance\n",
    "def evaluate_model(model_name, model, test_h2o, y_test):\n",
    "    try:\n",
    "        # Validation performance\n",
    "        test_performance = model.model_performance(test_data=test_h2o)\n",
    "        print(f\"\\nTest Performance for {model_name}:\")\n",
    "        print(test_performance)\n",
    "\n",
    "        # Extracting predictions\n",
    "        predictions = model.predict(test_h2o).as_data_frame().values.flatten()\n",
    "\n",
    "        # Calculate additional metrics using sklearn\n",
    "        mse = mean_squared_error(y_test, predictions)\n",
    "        rmse = np.sqrt(mse)\n",
    "        mae = mean_absolute_error(y_test, predictions)\n",
    "        r2 = r2_score(y_test, predictions)\n",
    "\n",
    "        print(f\"\\nAdditional Evaluation Metrics for {model_name}:\")\n",
    "        print(f\"MSE: {mse}\")\n",
    "        print(f\"RMSE: {rmse}\")\n",
    "        print(f\"MAE: {mae}\")\n",
    "        print(f\"R^2 Score: {r2}\")\n",
    "\n",
    "        # Append results to the DataFrame\n",
    "        results.loc[len(results)] = [model_name, mse, rmse, mae, r2]\n",
    "    except Exception as e:\n",
    "        print(f\"Error evaluating model {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Performance for DeepLearning_model_python_1735461052018_31:\n",
      "ModelMetricsRegression: deeplearning\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.06630532219303646\n",
      "RMSE: 0.25749819842677824\n",
      "MAE: 0.19925882702258896\n",
      "RMSLE: 0.09276666964802921\n",
      "Mean Residual Deviance: 0.06630532219303646\n",
      "deeplearning prediction progress: |██████████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huawei\\OneDrive - Universiti Malaya\\Desktop\\SEMESTER 7\\WIE3007_Data-Mining\\Group Project\\data-mining-warehousing-wages-analysis\\venv\\lib\\site-packages\\h2o\\frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Additional Evaluation Metrics for DeepLearning_model_python_1735461052018_31:\n",
      "MSE: 0.06630532219303649\n",
      "RMSE: 0.2574981984267783\n",
      "MAE: 0.199258827022589\n",
      "R^2 Score: 0.9988442228252492\n",
      "\n",
      "Test Performance for StackedEnsemble_model_python_1735565212779_5:\n",
      "ModelMetricsRegressionGLM: stackedensemble\n",
      "** Reported on test data. **\n",
      "\n",
      "MSE: 0.5516425154961121\n",
      "RMSE: 0.7427264068929501\n",
      "MAE: 0.536177505742845\n",
      "RMSLE: NaN\n",
      "Mean Residual Deviance: 0.5516425154961121\n",
      "R^2: 0.990384243572841\n",
      "Null degrees of freedom: 1169\n",
      "Residual degrees of freedom: 1167\n",
      "Null deviance: 67121.28489254977\n",
      "Residual deviance: 645.4217431304512\n",
      "AIC: 2632.3357482544166\n",
      "stackedensemble prediction progress: |███████████████████████████████████████████| (done) 100%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Huawei\\OneDrive - Universiti Malaya\\Desktop\\SEMESTER 7\\WIE3007_Data-Mining\\Group Project\\data-mining-warehousing-wages-analysis\\venv\\lib\\site-packages\\h2o\\frame.py:1983: H2ODependencyWarning: Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using multi-thread, install polars and pyarrow and use it as pandas_df = h2o_df.as_data_frame(use_multi_thread=True)\n",
      "\n",
      "  warnings.warn(\"Converting H2O frame to pandas dataframe using single-thread.  For faster conversion using\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Additional Evaluation Metrics for StackedEnsemble_model_python_1735565212779_5:\n",
      "MSE: 0.5516425154961121\n",
      "RMSE: 0.7427264068929501\n",
      "MAE: 0.5361775057428452\n",
      "R^2 Score: 0.990384243572841\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each loaded model\n",
    "for model_name, model in loaded_models.items():\n",
    "    evaluate_model(model_name, model, test_h2o, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Evaluation Results:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>MSE</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DeepLearning_model_python_1735461052018_31</td>\n",
       "      <td>0.066305</td>\n",
       "      <td>0.257498</td>\n",
       "      <td>0.199259</td>\n",
       "      <td>0.998844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>StackedEnsemble_model_python_1735565212779_5</td>\n",
       "      <td>0.551643</td>\n",
       "      <td>0.742726</td>\n",
       "      <td>0.536178</td>\n",
       "      <td>0.990384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Model       MSE      RMSE       MAE  \\\n",
       "0    DeepLearning_model_python_1735461052018_31  0.066305  0.257498  0.199259   \n",
       "1  StackedEnsemble_model_python_1735565212779_5  0.551643  0.742726  0.536178   \n",
       "\n",
       "         R2  \n",
       "0  0.998844  \n",
       "1  0.990384  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display and save the evaluation results\n",
    "print(\"\\nModel Evaluation Results:\")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Evaluate each model\n",
    "# for model_name, model in loaded_models.items():\n",
    "#     try:\n",
    "#         # Check if model is from scikit-learn or H2O\n",
    "#         if isinstance(model, h2o.estimators.estimator_base.H2OEstimator):\n",
    "#             h2o_test = h2o.H2OFrame(X_test)\n",
    "#             predictions = model.predict(h2o_test).as_data_frame(use_multi_thread=True)[\"predict\"]\n",
    "#             predictions_proba = model.predict(h2o_test).as_data_frame(use_multi_thread=True)\n",
    "#         else:\n",
    "#             predictions = model.predict(X_test)\n",
    "#             predictions_proba = model.predict_proba(X_test)\n",
    "\n",
    "#         # Compute metrics\n",
    "#         accuracy = accuracy_score(y_test, predictions)\n",
    "#         precision = precision_score(y_test, predictions, average=\"weighted\")\n",
    "#         recall = recall_score(y_test, predictions, average=\"weighted\")\n",
    "#         f1 = f1_score(y_test, predictions, average=\"weighted\")\n",
    "#         auc_roc = roc_auc_score(y_test, predictions_proba, multi_class=\"ovr\")\n",
    "\n",
    "#         # Append results\n",
    "#         results = results.append({\n",
    "#             \"Model\": model_name,\n",
    "#             \"Accuracy\": accuracy,\n",
    "#             \"Precision\": precision,\n",
    "#             \"Recall\": recall,\n",
    "#             \"F1-Score\": f1,\n",
    "#             \"AUC-ROC\": auc_roc\n",
    "#         }, ignore_index=True)\n",
    "\n",
    "#     except Exception as e:\n",
    "#         print(f\"Error evaluating model {model_name}: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Display the results table\n",
    "# print(results)\n",
    "\n",
    "# # Plot the results\n",
    "# results.set_index(\"Model\").plot(kind=\"bar\", figsize=(10, 6))\n",
    "# plt.title(\"Model Performance Metrics\")\n",
    "# plt.ylabel(\"Score\")\n",
    "# plt.xticks(rotation=45)\n",
    "# plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
